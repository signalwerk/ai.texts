# AI · Is it ethical to learn?

Artificial intelligence (AI) is a rapidly growing technology with transformative potential, but its increasing sophistication raises ethical questions, regarding the data it uses.

In this post, we will explore some concerns around AI learning on copyrighted material, as well as touch some implications with copyleft material. There are many other ethical concerns about AI<sup>1</sup>. For a start, we focus on the underlaying datasets.

## Learning on Copyrighted material

Copyright originated in England in the 1700s and was not a product of any inherent, natural law<sup>2</sup>, but rather a man-made construct designed to regulate the reproduction and distribution of books<sup>3</sup>. Over time, copyright laws expanded to cover other types of creative works, such as music, art, photography and source code. These laws were, in its beginning, born out of a desire to control and profit from the burgeoning market of printed material, which saw an explosion in literacy rates and a corresponding surge in the dissemination of ideas and texts across Europe.
The extension of copyright laws beyond their original purpose has had far-reaching consequences for society, from the ever-increasing cost of academic journals<sup>4</sup> and textbooks to the widespread use of DRM (Digital Rights Management) technologies that restrict access to digital content. Despite criticism<sup>5</sup> that the current application of copyright law is not well-suited to the digital age, it remains the legal framework that has been in place for over three centuries. While it is true that the rise of the internet and digital technologies has fundamentally altered the landscape of content creation<sup>6</sup> and dissemination, the existing legal framework of copyright has struggled to keep pace with these changes. This couldn’t be more true in the context of large language models in AI that are trained on vast amounts of data, much of which is generated by humans who never agreed to be included in a training set. What are the potential consequences of using copyrighted material for AI training? What is the consequence of learning not only by a human but also by machines?
Gathered know-how based on learning was traditionally attached to a subject, but this concept is now mimicked by machines and the resulting models become a codex of deterministic output. If an AI system is learning on copyrighted material, the resulting model could be sued for infringement or face other legal consequences<sup>7</sup>. The metaphor «Standing on the shoulders of giants.»<sup>8</sup> highlights the idea of cultural progress and the importance of building on existing knowledge rather than constantly starting from scratch. Does this only apply to humans and their learning?
All this raises serious ethical concerns about the use of copyrighted material for learning.
As such, it is essential that policymakers, industry stakeholders, and the broader public engage in a robust and ongoing discussion about the role of copyright – not only – in the development of AI and related technologies, and work together to ensure that these technologies are serving the good of democracy and prosperity for all of us.

## Learning on copyleft material

Another ethical concern with AI learning is the use of material in the training set that contains copyleft works. Copyleft is a licensing strategy that requires any modified or derivative work to also be released under the same licence, thereby promoting the free sharing and open development of derivative works. For instance, if an AI system is trained on source code with copy-left material, any software developed using that system could also be seen as subject to the same licence terms. This could limit the commercial usage of the resulting models, as it would be required to be distributed under an open-source licence. Additionally, the use of copy-left material for AI training could lead to legal disputes and confusion about ownership and licensing of the resulting AI system<sup>9</sup>. The issue of copy-left, as well as copyright, appears to be an unaddressed problem in the context of learning, which was previously not applicable to humans.

## Access to information

AI also raises questions about fairness and access to information. If the training data is proprietary, it may not be accessible to review, which will lead to biases in the resulting AI systems<sup>10</sup>. Proprietary data in general can limit opportunities for innovation and competition. If a few large companies have exclusive access to valuable data sets, it may be challenging for new players to enter the market and develop better solutions. Furthermore, copyright owners may have the power to influence what data is used for AI training, which could limit the scope and potential of the resulting models. The situation is even more problematic than existing copyright enforcement since there are not only copyright holders and access barriers to works, but also obstacles to the outcome of interpreting these materials, with access to these services being limited by paywalls controlled by a capitalist system driven by corporations and their shareholders.

## Conclusion

Given the potential ethical concerns around AI learning and its applications<sup>11, 12, 13</sup>, it is crucial to develop clear and comprehensive guidelines for the use of data in AI training. Not only inside companies, but also on a legal level. This includes guidelines for the use of copyrighted and copyleft material. Such guidelines could help ensure that AI systems are trained in an ethical and responsible manner, while also promoting fairness, access to information, and innovation.

As AI is a new and constantly developing technology that will play a major role in shaping our future, the incorporation of copyrighted and copy-left material in AI learning raises serious ethical considerations, such as fairness, information accessibility, and ownership, emphasizing the need for continued discussions and debates on the ethical implications of AI and the development of explicit and thorough guidelines for its application.

---

This blog post was co-authored and edited with the help of ChatGPT. In my role as a free software advocate at Liip, I'm aware of the ethical and licence implications this could have. Nevertheless, this text is licensed as [creative commons (CC BY-SA 2.0)](https://creativecommons.org/licenses/by-sa/2.0/), it's uncertain whether copyright truly belongs to the losers<sup>14</sup>.

---

### Footnotes and additional reading suggestions

1. Ethics in the Digital Domain, Robert S. Fortner, 2021
2. [Wikipedia · Natural law](https://en.wikipedia.org/wiki/Natural_law)
3. [Wikipedia · History of copyright](https://en.wikipedia.org/wiki/History_of_copyright)
4. [University of Missouri · Journal Prices Increase More than True Inflation](https://library.missouri.edu/news/lottes-health-sciences-library/scholarly-publishing-and-the-health-sciences-library)
5. [I think that conversations are the best, biggest thing that Free Software has to offer its user, 2015](https://web.archive.org/web/20161024143027/http://conversations.tools/150211_PRINT.pdf)
6. [Giving What You Don't Have](https://artwarez.org/projects/GWYDH/dockray.html)
7. [The Verge · Getty Images sues AI art generator Stable Diffusion in the US for copyright infringement](https://www.theverge.com/2023/2/6/23587393/ai-art-copyright-lawsuit-getty-images-stable-diffusion)
8. [Isaac Newton letter to Robert Hooke, 1675](https://discover.hsp.org/Record/dc-9792/Description)
9. [Legal Playbook For Natural Language Processing Researchers, 2022](https://bigscience.huggingface.co/blog/legal-playbook-for-natural-language-processing-researchers)
10. [Reuters · Amazon scraps secret AI recruiting tool that showed bias against women](https://www.reuters.com/article/us-amazon-com-jobs-automation-insight/amazon-scraps-secret-ai-recruiting-tool-that-showed-bias-against-women-idUSKCN1MK08G)
11. [Tages-Anzeiger · Die Verwaltung darf jetzt künstliche Intelligenz nutzen – doch sie muss aufpassen](https://www.tagesanzeiger.ch/die-verwaltung-darf-jetzt-kuenstliche-intelligenz-nutzen-doch-sie-muss-aufpassen-370090350992)
12. [Position der Digitalen Gesellschaft zur Regulierung von automatisierten Entscheidungssystemen](https://www.digitale-gesellschaft.ch/uploads/2022/02/Position-der-Digitalen-Gesellschaft-zur-Regulierung-von-automatisierten-Entscheidungssystemen-1.0.pdf)
13. Our Final Invention, James Barrat, 2013
14. Wall and Piece, Banksy, 2006



